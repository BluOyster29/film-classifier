{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('data/train_df.csv')\n",
    "test_csv = pd.read_csv('data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upto = 200\n",
    "test_upto = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Genre Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_genres(genre):\n",
    "    genre_set = []\n",
    "\n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "\n",
    "            if g not in genre_set:\n",
    "                genre_set.append(g)\n",
    "\n",
    "        idx2genre = dict(enumerate(genre_set))\n",
    "        genre2idx = {g : idx for idx, g in idx2genre.items()}\n",
    "    \n",
    "    return idx2genre, genre2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def count_genre(genre, genre2idx):\n",
    "    \n",
    "    genre_counts = {genre : 0 for genre in genre2idx.keys()}\n",
    "    \n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "            \n",
    "            genre_counts[g] += 1\n",
    "            \n",
    "    return genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_genres(genres, genre2idx):\n",
    "    \n",
    "    encoded_genres = []\n",
    "    \n",
    "    vector_size = len(genre2idx)\n",
    "    \n",
    "    for i in genres:\n",
    "            \n",
    "        empty_vec = np.zeros(vector_size)    \n",
    "        encoded = [genre2idx[x.strip()] for x in i.split(',')]\n",
    "        \n",
    "        for i in encoded:\n",
    "            empty_vec[i] = 1\n",
    "            \n",
    "        encoded_genres.append(empty_vec)\n",
    "        \n",
    "    return encoded_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_genre(genre, genre2idx):\n",
    "    \n",
    "    encoded_genre = torch.LongTensor([genre2idx[g.strip()] for g in genre])\n",
    "        \n",
    "    return encoded_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = train_csv['genre'].tolist()[:train_upto]\n",
    "test_genre = test_csv['genre'].tolist()[:test_upto]\n",
    "idx2genre, genre2idx = get_genres(genre)\n",
    "genre_counts = count_genre(genre, genre2idx)\n",
    "encoded_genres = encode_genres(genre, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_genres = encode_genres(test_genre, genre2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Plot and Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reg_remove(plot):\n",
    "    remove_non_words = re.compile(r'[^\\w -]')\n",
    "    clean = re.sub(remove_non_words, '', plot)\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_vocab(plots, train=None):\n",
    "    \n",
    "    vocab = {}\n",
    "    processed_plots = []\n",
    "    \n",
    "    for plot in tqdm(plots):\n",
    "\n",
    "        plot = reg_remove(plot.lower()).split(' ')\n",
    "        plot.insert(0, '<start>')\n",
    "        plot.append('<end>')\n",
    "        \n",
    "        if train:\n",
    "            for token in plot:\n",
    "\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab) +1 \n",
    "        \n",
    "        processed_plots.append(plot)\n",
    "    \n",
    "    if train:\n",
    "        idx2wrd = {idx : wrd for wrd,idx in vocab.items()}\n",
    "        return vocab, idx2wrd, processed_plots\n",
    "    \n",
    "    return processed_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = train_csv['plot'].tolist()[:train_upto]\n",
    "test_plots=test_csv['plot'].tolist()[:test_upto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56597af4a649493c809eaecbd5bd7662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrd2idx, idx2wrd, processed_plots = build_vocab(plots, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d014602a584e2bbd23c7ad5841bbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_processed_plots = build_vocab(test_plots, train=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode(plot, wrd2idx):\n",
    "    \n",
    "    encoded_plot = []\n",
    "    \n",
    "    for token in plot:\n",
    "        \n",
    "        if token in wrd2idx:\n",
    "            encoded_plot.append(wrd2idx[token])\n",
    "            \n",
    "        else:\n",
    "            encoded_plot.append(len(wrd2idx)+1)\n",
    "            \n",
    "    return encoded_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_plots(plots, wrd2idx):\n",
    "    \n",
    "    encoded = []\n",
    "    \n",
    "    for i in tqdm(plots):\n",
    "        encoded.append(torch.LongTensor(encode(i, wrd2idx)))\n",
    "        \n",
    "    return pad_sequence(encoded,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3430906ac446c3817f4cbd20ca1a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a26501f4f24e5ea105ce79ca5e67a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded = encode_plots(processed_plots, wrd2idx)\n",
    "test_encoded = encode_plots(test_processed_plots, wrd2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmClassifier(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FilmClassifier(encoded, encoded_genres)\n",
    "test_dataset = FilmClassifier(test_encoded, test_encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,shuffle=True, batch_size=20)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = super(SpatialDropout, self).forward(x)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, vocab_size, hidden_dim, \n",
    "                 embed_dim, n_layers, output_size, batch_size):\n",
    "        super(rnn, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        self.lstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim*2, 1)\n",
    "        self.fc_aux_out = nn.Linear(hidden_dim*2, output_size-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        embedded = self.embedding_dropout(self.embed(x))\n",
    "        \n",
    "        h_1, _ = self.lstm1(embedded)\n",
    "        h_2, _ = self.lstm2(h_1)\n",
    "        \n",
    "        avg_pool = torch.mean(h_2, 1)\n",
    "        max_pool, _ = torch.max(h_2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        \n",
    "        h_lin_1 = F.relu(self.fc1(h_conc))\n",
    "        h_li_2 = F.relu(self.fc2(h_conc))\n",
    "        h_conc_linear = torch.cat((h_lin_1, h_li_2), 1)\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear\n",
    "        result = self.fc_out(hidden)\n",
    "        \n",
    "        aux_result = self.fc_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(wrd2idx) + 2\n",
    "embed_dim = 128\n",
    "hidden_dim=128\n",
    "output_size = len(genre2idx)\n",
    "input_size=623\n",
    "n_layers = 1\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn(input_size, vocab_size, hidden_dim,\n",
    "            embed_dim, n_layers, output_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "NUM_EPOCHS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn(\n",
       "  (embed): Embedding(4940, 128)\n",
       "  (embedding_dropout): SpatialDropout(p=0.3, inplace=False)\n",
       "  (lstm1): LSTM(128, 128, batch_first=True)\n",
       "  (lstm2): LSTM(128, 128, batch_first=True)\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc_out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (fc_aux_out): Linear(in_features=256, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, NUM_EPOCHS):\n",
    "    \n",
    "    for epoch in tqdm(range(0, NUM_EPOCHS), total=NUM_EPOCHS):\n",
    "        \n",
    "        model.train()\n",
    "        avg_loss = 0\n",
    "        for i in tqdm(train_dataloader):\n",
    "\n",
    "            x = i[0].to(device)\n",
    "            y = i[1].to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_dataloader)\n",
    "        \n",
    "\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d951832562444d7bb7692d7e88082fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e592c9d4914b1fa4ea98dad5acb28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5191813400717776\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(train_dataloader, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(preds):\n",
    "    empty = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i > 0.5:\n",
    "            empty.append(1)\n",
    "            \n",
    "        else:\n",
    "            empty.append(0)\n",
    "            \n",
    "    return empty\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trained_model, test_dataloader, urlystop):\n",
    "    preds = []\n",
    "    true = []\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "    num = 0\n",
    "    for i in tqdm(test_dataloader, total=urlystop):\n",
    "\n",
    "        if num == urlystop:\n",
    "            break\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "\n",
    "        out = model(x)\n",
    "        pred = sigmoid(out.detach().numpy())\n",
    "        preds.append(get_index(pred[0]))\n",
    "        true.append(y.numpy()[0])\n",
    "        num += 1\n",
    "    \n",
    "    return np.array(preds), np.array(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082d39d1e52f4130be37b2cd0a0de6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pres, true = test(trained_model, test_dataloader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    ModelsPerformance = {}\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro', zero_division=True)\n",
    "\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro', zero_division=True)\n",
    "    \n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    \n",
    "    ModelsPerformance[modelName] = micro_f1\n",
    "    \n",
    "    return ModelsPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = metricsReport('Micro-F1 Score', true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Micro-F1 Score': 0.2747252747252747}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = np.all(pres == true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    \n",
    "    return temp / y_true.shape[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22233333333333336"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_true[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_true[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22233333333333336"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_pred[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_pred[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamming_Loss(y_true, y_pred):\n",
    "    temp=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += np.size(y_true[i] == y_pred[i]) - np.count_nonzero(y_true[i] == y_pred[i])\n",
    "    return temp/(y_true.shape[0] * y_true.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11478260869565217"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamming_Loss(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = multilabel_confusion_matrix(true,pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.7045454545454545\n",
      "0.8333333333333333\n",
      "0.6428571428571428\n",
      "0.45\n",
      "0.75\n",
      "0.40909090909090906\n",
      "0.5\n",
      "0.575\n",
      "0.4523809523809524\n",
      "0.75\n",
      "0.5\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.6736842105263158\n",
      "0.85\n",
      "0.625\n",
      "0.4736842105263158\n",
      "0.75\n",
      "0.7272727272727273\n",
      "0.4772727272727273\n",
      "0.45454545454545453\n",
      "0.75\n",
      "0.4772727272727273\n",
      "0.875\n",
      "0.75\n",
      "1.0\n",
      "0.7249999999999999\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.75\n",
      "0.7272727272727273\n",
      "0.475\n",
      "0.75\n",
      "0.9772727272727273\n",
      "0.625\n",
      "0.5952380952380952\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.475\n",
      "0.9772727272727273\n",
      "0.75\n",
      "0.9782608695652174\n",
      "0.75\n",
      "0.625\n",
      "0.45454545454545453\n",
      "0.7272727272727273\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.6190476190476191\n",
      "0.5\n",
      "0.7272727272727273\n",
      "0.5952380952380952\n",
      "0.4736842105263158\n",
      "0.6190476190476191\n",
      "0.9761904761904762\n",
      "0.8333333333333333\n",
      "0.6388888888888888\n",
      "0.625\n",
      "1.0\n",
      "0.625\n",
      "0.5\n",
      "0.6190476190476191\n",
      "0.6190476190476191\n",
      "0.4772727272727273\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.475\n",
      "0.7045454545454545\n",
      "0.7045454545454545\n",
      "0.6190476190476191\n",
      "1.0\n",
      "0.4772727272727273\n",
      "0.4565217391304348\n",
      "0.75\n",
      "0.4736842105263158\n",
      "0.6428571428571428\n",
      "0.6190476190476191\n",
      "0.4565217391304348\n",
      "0.8095238095238093\n",
      "0.7249999999999999\n",
      "1.0\n",
      "0.6\n",
      "0.6388888888888888\n",
      "0.4782608695652174\n",
      "0.5714285714285714\n",
      "0.625\n",
      "0.47619047619047616\n",
      "0.8333333333333333\n",
      "0.7\n",
      "0.8\n",
      "0.45454545454545453\n",
      "0.75\n",
      "0.75\n",
      "0.5833333333333334\n",
      "0.7000000000000001\n",
      "0.6666666666666666\n",
      "0.6190476190476191\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in zip(true, preds):\n",
    "    \n",
    "    score = roc_auc_score(i[0], i[1])\n",
    "    scores.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: \n"
     ]
    }
   ],
   "source": [
    "print('AUC: '.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_image(filename, from_path):\n",
    "    \n",
    "    if from_path == False:\n",
    "        \n",
    "        input_image = Image.open(filename)\n",
    "        transformed = transform(input_image)\n",
    "        filename = filename.split('/')[-1][:-5]\n",
    "        filename = 'data/processed_posters/{}-processed.jpeg'.format(filename)\n",
    "\n",
    "        output_image(transformed, filename)\n",
    "        return transformed\n",
    "\n",
    "    else:\n",
    "        \n",
    "        transformed = transform(Image.open(filename))\n",
    "        return transformed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def output_image(image, filename):\n",
    "    \n",
    "    image = ToPILImage()(invTrans(image))\n",
    "    image.save(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "processed = torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "film_ids = [i[13:-5] for i in df['poster_path'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = film_dataset(film_ids, encoded, processed, encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_plot(idx2wrd, plot):\n",
    "    \n",
    "    plot = [int(i) for i in list(plot)]\n",
    "    decoded = [idx2wrd[i] for i in plot if i != 0]\n",
    "    \n",
    "    return ' '.join(decoded[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_genre(genre, idx2genre):\n",
    "    \n",
    "    genre = [int(i) for i in list(genre)]\n",
    "    decoded = [idx2genre[i] for i in genre]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_genre(dataset[1]['genre'], idx2genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "    invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])\n",
    "    pil_image = ToPILImage()(invTrans(image))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = view_image(dataset[23]['poster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col, row in df.iterrows():\n",
    "    print(row)\n",
    "    genre = encode_genre(row['genre'], genre2idx)\n",
    "    plot = encode_plot(row['plot'], wrd2idx)\n",
    "    print(row['poster_path'])\n",
    "    poster = process_image(row['poster_path'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, wrd2idx, genre2idx):\n",
    "        \n",
    "        self.film_id = []\n",
    "        self.genre = []\n",
    "        self.plot = []\n",
    "        self.poster = []\n",
    "        self.failed = []\n",
    "        \n",
    "        self.wrd2idx = wrd2idx\n",
    "        self.genre2idx = genre2idx\n",
    "        \n",
    "        for col, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            self.film_id.append(row['id'])\n",
    "            self.genre.append(encode_genre(row['genre'], genre2idx))\n",
    "            self.plot.append(encode_plot(row['plot'], wrd2idx))\n",
    "            self.poster.append(process_image(row['poster_path'], True))\n",
    "            self.failed.append(row)\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = film_dataset(df[:50], wrd2idx, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, film_id, plot, poster, genre):\n",
    "        \n",
    "        self.film_id = film_id\n",
    "        self.plot = plot\n",
    "        self.poster = poster\n",
    "        self.genre = genre\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
