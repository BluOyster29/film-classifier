{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movie_db_2000.csv')\n",
    "a = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upto = 200\n",
    "test_upto = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('data/movie_db_2000.csv')[:train_upto]\n",
    "test_csv = pd.read_csv('data/movie_db_2000.csv')[train_upto:test_upto].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Genre Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_genres(genre):\n",
    "    genre_set = []\n",
    "    num=0\n",
    "    failed=[]\n",
    "    for i in genre:\n",
    "        try:\n",
    "            genres = i.split(',')\n",
    "\n",
    "            for g in genres:\n",
    "\n",
    "                g = g.strip()\n",
    "\n",
    "                if g not in genre_set:\n",
    "                    genre_set.append(g)\n",
    "        except:\n",
    "            failed.append(num)\n",
    "        num+=1\n",
    "        \n",
    "    idx2genre = dict(enumerate(genre_set))\n",
    "    genre2idx = {g : idx for idx, g in idx2genre.items()}\n",
    "    \n",
    "    return idx2genre, genre2idx, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def count_genre(genre, genre2idx):\n",
    "    \n",
    "    genre_counts = {genre : 0 for genre in genre2idx.keys()}\n",
    "    \n",
    "    for i in genre:\n",
    "        try:\n",
    "            genres = i.split(',')\n",
    "\n",
    "            for g in genres:\n",
    "\n",
    "                g = g.strip()\n",
    "\n",
    "                genre_counts[g] += 1\n",
    "                \n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    return genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode_genres(genres, genre2idx):\n",
    "    \n",
    "    encoded_genres = []\n",
    "    failed=[]\n",
    "    vector_size = len(genre2idx)\n",
    "    num = 0\n",
    "    for i in genres:\n",
    "        try:\n",
    "            empty_vec = np.zeros(vector_size)    \n",
    "            encoded = [genre2idx[x.strip()] for x in i.split(',')]\n",
    "\n",
    "            for i in encoded:\n",
    "                empty_vec[i] = 1\n",
    "        except:\n",
    "            failed.append(num)\n",
    "        num+=1\n",
    "        encoded_genres.append(empty_vec)\n",
    "        \n",
    "    return encoded_genres, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode_genre(genre, genre2idx):\n",
    "    \n",
    "    encoded_genre = torch.LongTensor([genre2idx[g.strip()] for g in genre])\n",
    "        \n",
    "    return encoded_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = train_csv['genre'].tolist()\n",
    "test_genre = test_csv['genre'].tolist()\n",
    "idx2genre, genre2idx, failed = get_genres(genre)\n",
    "genre_counts = count_genre(genre, genre2idx)\n",
    "encoded_genres,failed = encode_genres(genre, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_genres, failed = encode_genres(test_genre, genre2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Plot and Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/glove_vectors/glove.840B.300d.txt', 'r') as file:\n",
    "#     glove_vectors = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = []\n",
    "# #vectors = []\n",
    "# for i in tqdm(glove_vectors):\n",
    "    \n",
    "#     i = i[:-1]\n",
    "#     i = i.split(' ')\n",
    "#     tokens.append(i[0])\n",
    "#     #vectors.append(np.array([float(x) for x in i[1:]]))\n",
    "    \n",
    "# vecs = torch.Tensor(vectors)\n",
    "# pretrained_wrd2idx = {wrd : idx for idx,wrd in dict(enumerate(tokens)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def reg_remove(plot):\n",
    "    remove_non_words = re.compile(r'[^\\w -]')\n",
    "    clean = re.sub(remove_non_words, '', plot)\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(plots, train=None):\n",
    "    \n",
    "    vocab = {}\n",
    "    processed_plots = []\n",
    "    failed = []\n",
    "    num = 0\n",
    "    for plot in tqdm(plots):\n",
    "        try:\n",
    "            plot = reg_remove(plot.lower()).split(' ')\n",
    "            plot.insert(0, '<start>')\n",
    "            plot.append('<end>')\n",
    "\n",
    "            if train:\n",
    "                for token in plot:\n",
    "\n",
    "                    if token not in vocab:\n",
    "                        vocab[token] = len(vocab) +1 \n",
    "\n",
    "            processed_plots.append(plot)\n",
    "            \n",
    "        except:\n",
    "            failed.append(num)\n",
    "        \n",
    "        num += 1\n",
    "    if train:\n",
    "        idx2wrd = {idx : wrd for wrd,idx in vocab.items()}\n",
    "        return vocab, idx2wrd, processed_plots, failed\n",
    "    \n",
    "    return processed_plots, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = train_csv['plot'].tolist()[:train_upto]\n",
    "test_plots=test_csv['plot'].tolist()[:test_upto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e193c735b54bf5a3506f3f5cc2a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wrd2idx, idx2wrd, processed_plots, failed = build_vocab(plots, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f314b5e0e0f7426c87c17d3c265b1e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_processed_plots, test_failed = build_vocab(test_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode(plot, wrd2idx):\n",
    "    \n",
    "    encoded_plot = []\n",
    "    \n",
    "    for token in plot:\n",
    "        \n",
    "        if token in wrd2idx:\n",
    "            encoded_plot.append(wrd2idx[token])\n",
    "            if type(wrd2idx[token]) != int:\n",
    "                print('FUUUUCK')\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            encoded_plot.append(len(wrd2idx)+1)\n",
    "\n",
    "    return np.array(encoded_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode_plots(plots, wrd2idx, pretrained_wrd2idx=None, use_pretrained=None):\n",
    "    \n",
    "    if use_pretrained:\n",
    "        wrd2idx = pretrained_wrd2idx\n",
    "        \n",
    "    encoded = []\n",
    "    \n",
    "    for i in tqdm(plots):\n",
    "        encoded.append(torch.LongTensor(encode(i, wrd2idx)))\n",
    "        \n",
    "    return pad_sequence(encoded,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_vocab = dict(enumerate(tokens))\n",
    "#pretrained_wrd2idx = {wrd : idx for idx, wrd in pretrained_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encode_plots(processed_plots, wrd2idx, use_pretrained=None)\n",
    "test_encoded = encode_plots(test_processed_plots, wrd2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9,
     16
    ]
   },
   "outputs": [],
   "source": [
    "class FilmClassifier(Dataset):\n",
    "    \n",
    "    def __init__(self, df, X, y, from_path):\n",
    "        \n",
    "        self.df = df\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.from_path = from_path\n",
    "    \n",
    "    def processed_path(self, path):\n",
    "        path = path.split('/')\n",
    "        path[1] = 'processed_posters'\n",
    "        x = path[2].split('.')\n",
    "        path[2] = '{}-processed.jpeg'.format(x[0])\n",
    "        return '/'.join(path)\n",
    "    \n",
    "    def process_image(self, filename):\n",
    "    \n",
    "        if self.from_path == False:\n",
    "\n",
    "            input_image = Image.open(filename)\n",
    "            transformed = transform(input_image)\n",
    "            filename = filename.split('/')[-1][:-5]\n",
    "            filename = 'data/processed_posters/{}-processed.jpeg'.format(filename)\n",
    "            #output_image(transformed, filename)\n",
    "            return transformed\n",
    "\n",
    "        else:\n",
    "\n",
    "            transformed = transform(Image.open(filename))\n",
    "            return transformed\n",
    "    \n",
    "    def title_search(self, title):\n",
    "        \n",
    "        return self.df[self.df['title'] == title]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {'id' : self.df.loc[idx]['id'],\n",
    "                'title' : self.df.loc[idx]['title'],\n",
    "                'genre' : self.df.loc[idx]['genre'],\n",
    "                'poster' : self.process_image(self.df.loc[idx]['poster_path']),\n",
    "                'plot' : self.df.loc[idx]['plot'],\n",
    "                'encoded_plot' : self.X[idx],\n",
    "                'encoded_genre' : self.y[idx]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FilmClassifier(train_csv, encoded, encoded_genres, False)\n",
    "test_dataset = FilmClassifier(test_csv, test_encoded, test_encoded_genres, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,shuffle=True, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.title_search('Toy Story')['plot'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(dataset):\n",
    "    \n",
    "    failed=[]\n",
    "    tester = iter(dataset)\n",
    "    \n",
    "    for i in tqdm(range(len(dataset)), total=len(dataset)):\n",
    "        \n",
    "        a = next(tester)\n",
    "        \n",
    "            \n",
    "    return failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f=validate_data(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataloader.pkl', 'wb') as file:\n",
    "#     pickle.dump(test_dataloader,file)\n",
    "    \n",
    "\n",
    "# with open('dataloader.pkl', 'rb') as file:\n",
    "#     te = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = super(SpatialDropout, self).forward(x)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, vocab_size, hidden_dim, \n",
    "                 embed_dim, n_layers, output_size, batch_size):\n",
    "        super(rnn, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            \n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.gru1 = nn.GRU(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.gru2 = nn.GRU(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim*2, 1)\n",
    "        self.fc_aux_out = nn.Linear(hidden_dim*2, output_size-1)\n",
    "        \n",
    "    def forward(self, x, features, use_features):\n",
    "        \n",
    "        embedded = self.embedding_dropout(self.embed(x))\n",
    "        if use_features==True:\n",
    "            h = features.expand(self.n_layers, -1,-1)\n",
    "            print(h.shape)\n",
    "            out, h_1 = self.gru1(embedded, h)\n",
    "            h_2, _ = self.gru2(out, h_1)\n",
    "        else:\n",
    "            out, h_1 = self.gru1(embedded)\n",
    "            h_2, _ = self.gru2(out)\n",
    "            \n",
    "        avg_pool = torch.mean(h_2, 1)\n",
    "        max_pool, _ = torch.max(h_2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        \n",
    "        h_lin_1 = F.relu(self.fc1(h_conc))\n",
    "        h_li_2 = F.relu(self.fc2(h_conc))\n",
    "        h_conc_linear = torch.cat((h_lin_1, h_li_2), 1)\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear\n",
    "        result = self.fc_out(hidden)\n",
    "        \n",
    "        aux_result = self.fc_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(wrd2idx) + 2\n",
    "embed_dim = 300\n",
    "hidden_dim=512\n",
    "output_size = len(genre2idx)\n",
    "input_size=623\n",
    "n_layers = 1\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn(input_size, vocab_size, hidden_dim,\n",
    "            embed_dim, n_layers, output_size, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "NUM_EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "#feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "for epoch in tqdm(range(0, NUM_EPOCHS), total=NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    feature_extractor.train()\n",
    "    avg_loss = 0\n",
    "    failed = []\n",
    "    \n",
    "    for i in tqdm(train_dataloader):\n",
    "\n",
    "        x = i['encoded_plot'].to(device)\n",
    "        y = i['encoded_genre'].to(device)\n",
    "        img = i['poster'].to(device)\n",
    "\n",
    "        features = feature_extractor(img)\n",
    "        features=features.transpose(0,2).transpose(1,3).squeeze(0) \n",
    "        out = model(x, features, use_features=True, image_only=True)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "    print(avg_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(preds):\n",
    "    empty = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i > 0.5:\n",
    "            empty.append(1)\n",
    "            \n",
    "        else:\n",
    "            empty.append(0)\n",
    "            \n",
    "    return empty\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trained_model, test_dataloader, urlystop, feature_extractor):\n",
    "    preds = []\n",
    "    set_true = []\n",
    "    true=[]\n",
    "    trained_model.eval()\n",
    "    trained_model.to('cuda:1')\n",
    "    feature_extractor.eval()\n",
    "\n",
    "    num = 0\n",
    "    for i in tqdm(test_dataloader, total=urlystop):\n",
    "        if num == urlystop:\n",
    "            break\n",
    "     \n",
    "        x = i['encoded_plot'].to('cuda:1')\n",
    "        y = i['encoded_genre'].to('cuda:1')\n",
    "        img = i['poster'].to('cuda:1')\n",
    "        features = feature_extractor(img)\n",
    "        features=features.transpose(0,2).transpose(1,3).squeeze(0) \n",
    "        out = model(x, features,use_features=True)\n",
    "        pred = sigmoid(out.cpu().detach().numpy())\n",
    "        preds.append(get_index(pred[0]))\n",
    "        set_true.append((i['genre'],i['title']))\n",
    "        num += 1\n",
    "        true.append(y.squeeze(0).cpu().numpy())\n",
    "        \n",
    "    \n",
    "    return np.array(preds), set_true, np.array(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, set_true,true = test(model, test_dataloader, len(test_dataloader), feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    ModelsPerformance = {}\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro', zero_division=True)\n",
    "\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro', zero_division=True)\n",
    "    \n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    \n",
    "    ModelsPerformance[modelName] = micro_f1\n",
    "    \n",
    "    return ModelsPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = metricsReport('Micro-F1 Score', true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exactmatch(true,pres):\n",
    "    correct=0\n",
    "    for t, p in zip(true,pres):\n",
    "        if list(t)==list(p):\n",
    "            correct+=1\n",
    "            \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for i,x in zip(true, pres):\n",
    "    if i.any() == x.any():\n",
    "        accuracy += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_exactmatch(true,pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    \n",
    "    return temp / y_true.shape[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_true[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_true[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_pred[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_pred[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamming_Loss(y_true, y_pred):\n",
    "    temp=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += np.size(y_true[i] == y_pred[i]) - np.count_nonzero(y_true[i] == y_pred[i])\n",
    "    return temp/(y_true.shape[0] * y_true.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hamming_Loss(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = multilabel_confusion_matrix(true,pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in zip(true, pres):\n",
    "    try:\n",
    "        score = roc_auc_score(i[0], i[1])\n",
    "        scores.append(score)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pred(pred, idx2genre):\n",
    "    genres = []\n",
    "    num=0\n",
    "    for i in pred:\n",
    "        i = int(i)\n",
    "        if i != 0:\n",
    "            genres.append(idx2genre[num])\n",
    "                \n",
    "        num+=1\n",
    "    return '/'.join(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for t, pred in zip(set_true, pres):\n",
    "    #print(t)\n",
    "    true_gen='/'.join([i.strip() for i in t[0][0].split(',')])\n",
    "    decoded_pred = decode_pred(pred, idx2genre)\n",
    "    \n",
    "    print()\n",
    "    print('Film Title: {}'.format(t[1][0]))\n",
    "    print('True Genres: {}'.format(true_gen))\n",
    "    print('Pred Genres: {}'.format(decoded_pred))\n",
    "    \n",
    "    if true_gen==decoded_pred:\n",
    "        accuracy+=1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def decode_plot(idx2wrd, plot):\n",
    "    \n",
    "    plot = [int(i) for i in list(plot)]\n",
    "    decoded = [idx2wrd[i] for i in plot if i != 0]\n",
    "    \n",
    "    return ' '.join(decoded[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_genre(test_dataset[1], pres[0], idx2genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "    invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])\n",
    "    pil_image = ToPILImage()(invTrans(image))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = view_image(dataset[23]['poster'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
