{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/movie_db.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_df.csv')\n",
    "test = pd.read_csv('data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Genre Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "def get_genres(genre):\n",
    "    genre_set = []\n",
    "\n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "\n",
    "            if g not in genre_set:\n",
    "                genre_set.append(g)\n",
    "\n",
    "        idx2genre = dict(enumerate(genre_set))\n",
    "        genre2idx = {g : idx for idx, g in idx2genre.items()}\n",
    "    \n",
    "    return idx2genre, genre2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def count_genre(genre, genre2idx):\n",
    "    \n",
    "    genre_counts = {genre : 0 for genre in genre2idx.keys()}\n",
    "    \n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "            \n",
    "            genre_counts[g] += 1\n",
    "            \n",
    "    return genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_genres(genres, genre2idx):\n",
    "    \n",
    "    encoded_genres = []\n",
    "    \n",
    "    vector_size = len(genre2idx)\n",
    "    \n",
    "    for i in genres:\n",
    "            \n",
    "        empty_vec = np.zeros(vector_size)    \n",
    "        encoded = [genre2idx[x.strip()] for x in i.split(',')]\n",
    "        \n",
    "        for i in encoded:\n",
    "            empty_vec[i] = 1\n",
    "            \n",
    "        encoded_genres.append(empty_vec)\n",
    "        \n",
    "    return encoded_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_genre(genre, genre2idx):\n",
    "    \n",
    "    encoded_genre = torch.LongTensor([genre2idx[g.strip()] for g in genre])\n",
    "        \n",
    "    return encoded_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = train['genre'].tolist()\n",
    "test_genre = test['genre'].tolist()\n",
    "idx2genre, genre2idx = get_genres(genre)\n",
    "genre_counts = count_genre(genre, genre2idx)\n",
    "encoded_genres = encode_genres(genre, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_genres = encode_genres(test_genre, genre2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Plot and Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = train['plot'].tolist()\n",
    "test_plots=test['plot'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_remove(plot):\n",
    "    remove_non_words = re.compile(r'[^\\w -]')\n",
    "    clean = re.sub(remove_non_words, '', plot)\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(plots, train=None):\n",
    "    \n",
    "    vocab = {}\n",
    "    processed_plots = []\n",
    "    \n",
    "    for plot in tqdm(plots):\n",
    "\n",
    "        plot = reg_remove(plot.lower()).split(' ')\n",
    "        plot.insert(0, '<start>')\n",
    "        plot.append('<end>')\n",
    "        \n",
    "        if train:\n",
    "            for token in plot:\n",
    "\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab) +1 \n",
    "        \n",
    "        processed_plots.append(plot)\n",
    "    \n",
    "    if train:\n",
    "        idx2wrd = {idx : wrd for wrd,idx in vocab.items()}\n",
    "        return vocab, idx2wrd, processed_plots\n",
    "    \n",
    "    return processed_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274dbd39b2cb46ce8df1667d710fe619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4771.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wrd2idx, idx2wrd, processed_plots = build_vocab(plots, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c7b4513aa3475cb7c70092088db865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_processed_plots = build_vocab(test_plots, train=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(plot, wrd2idx):\n",
    "    \n",
    "    encoded_plot = []\n",
    "    \n",
    "    for token in plot:\n",
    "        \n",
    "        if token in wrd2idx:\n",
    "            encoded_plot.append(wrd2idx[token])\n",
    "            \n",
    "        else:\n",
    "            encoded_plot.append(len(wrd2idx)+1)\n",
    "            \n",
    "    return encoded_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_plots(plots, wrd2idx):\n",
    "    \n",
    "    encoded = []\n",
    "    \n",
    "    for i in tqdm(plots):\n",
    "        encoded.append(torch.LongTensor(encode(i, wrd2idx)))\n",
    "        \n",
    "    return pad_sequence(encoded,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3162c296a7b24b03a23ecedb0bad271b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4771.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc5d68ee8824aa780d7df5d8f4bff73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded = encode_plots(processed_plots, wrd2idx)\n",
    "test_encoded = encode_plots(test_processed_plots, wrd2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmClassifier(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FilmClassifier(encoded, encoded_genres)\n",
    "test_dataset = FilmClassifier(test_encoded, test_encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,shuffle=True, batch_size=128)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, vocab_size, hidden_dim, \n",
    "                 embed_dim, n_layers, output_size, batch_size):\n",
    "        super(rnn, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim*2, 1)\n",
    "        self.fc_aux_out = nn.Linear(hidden_dim*2, 23)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        embedded = self.embed(x)\n",
    "        \n",
    "        h_1, _ = self.lstm1(embedded)\n",
    "        h_2, _ = self.lstm2(h_1)\n",
    "        \n",
    "        avg_pool = torch.mean(h_2, 1)\n",
    "        max_pool, _ = torch.max(h_2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        \n",
    "        h_lin_1 = F.relu(self.fc1(h_conc))\n",
    "        h_li_2 = F.relu(self.fc2(h_conc))\n",
    "        h_conc_linear = torch.cat((h_lin_1, h_li_2), 1)\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear\n",
    "        result = self.fc_out(hidden)\n",
    "        \n",
    "        aux_result = self.fc_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(wrd2idx) + 2\n",
    "embed_dim = 300\n",
    "hidden_dim=68\n",
    "output_size = len(genre2idx)\n",
    "input_size=623\n",
    "n_layers = 1\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn(input_size, vocab_size, hidden_dim,\n",
    "            embed_dim, n_layers, output_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn(\n",
       "  (embed): Embedding(32425, 300)\n",
       "  (lstm1): LSTM(300, 68, batch_first=True)\n",
       "  (lstm2): LSTM(68, 68, batch_first=True)\n",
       "  (fc1): Linear(in_features=136, out_features=68, bias=True)\n",
       "  (fc2): Linear(in_features=136, out_features=68, bias=True)\n",
       "  (fc_out): Linear(in_features=136, out_features=1, bias=True)\n",
       "  (fc_aux_out): Linear(in_features=136, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0454d9a07334761a953588d37f99eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac4d1e5c3694b07af18faeb171485e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.38627289053946906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee50929b4ac4e219908a7822a8849ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2980972160859654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3af3219723c41cb8acfd4f6d6bafd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2967077740616074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025171c3b5c1418a8aca7bec7c11e8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2962800104391387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039d4d54dfe24a149bcbe310420a0cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.29017987420789476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878aac14d9784d59a3e7a97b8ba49161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2751561825157968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d908e9aad29b483c9953d44ce944fad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2544681615987384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4aea738c03429cade260f06d477a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.23430168213826824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae1d8315039449e9e7c072e40625abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.2177199230449715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393b09f11d5044b085e48b490881afc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.20011337313903832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(0, 10), total=NUM_EPOCHS):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for i in tqdm(train_dataloader):\n",
    "\n",
    "        x = i[0].to(device)\n",
    "        y = i[1].to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_dataloader)\n",
    "\n",
    "\n",
    "    print(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(preds):\n",
    "    empty = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i > 0.5:\n",
    "            empty.append(1)\n",
    "            \n",
    "        else:\n",
    "            empty.append(0)\n",
    "            \n",
    "    return empty\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e820e6ab7b6f4b13a36691cdbe437572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "true = []\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "\n",
    "num = 0\n",
    "for i in tqdm(test_dataloader, total=100):\n",
    "    \n",
    "    if num == 100:\n",
    "        break\n",
    "    x = i[0]\n",
    "    y = i[1]\n",
    "\n",
    "    out = model(x)\n",
    "    pred = sigmoid(out.detach().numpy())\n",
    "    preds.append(get_index(pred.tolist()[0]))\n",
    "    true.append(y.numpy()[0])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.7045454545454545\n",
      "0.8333333333333333\n",
      "0.6428571428571428\n",
      "0.45\n",
      "0.75\n",
      "0.40909090909090906\n",
      "0.5\n",
      "0.575\n",
      "0.4523809523809524\n",
      "0.75\n",
      "0.5\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.6736842105263158\n",
      "0.85\n",
      "0.625\n",
      "0.4736842105263158\n",
      "0.75\n",
      "0.7272727272727273\n",
      "0.4772727272727273\n",
      "0.45454545454545453\n",
      "0.75\n",
      "0.4772727272727273\n",
      "0.875\n",
      "0.75\n",
      "1.0\n",
      "0.7249999999999999\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.75\n",
      "0.7272727272727273\n",
      "0.475\n",
      "0.75\n",
      "0.9772727272727273\n",
      "0.625\n",
      "0.5952380952380952\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.475\n",
      "0.9772727272727273\n",
      "0.75\n",
      "0.9782608695652174\n",
      "0.75\n",
      "0.625\n",
      "0.45454545454545453\n",
      "0.7272727272727273\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.6190476190476191\n",
      "0.5\n",
      "0.7272727272727273\n",
      "0.5952380952380952\n",
      "0.4736842105263158\n",
      "0.6190476190476191\n",
      "0.9761904761904762\n",
      "0.8333333333333333\n",
      "0.6388888888888888\n",
      "0.625\n",
      "1.0\n",
      "0.625\n",
      "0.5\n",
      "0.6190476190476191\n",
      "0.6190476190476191\n",
      "0.4772727272727273\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.475\n",
      "0.7045454545454545\n",
      "0.7045454545454545\n",
      "0.6190476190476191\n",
      "1.0\n",
      "0.4772727272727273\n",
      "0.4565217391304348\n",
      "0.75\n",
      "0.4736842105263158\n",
      "0.6428571428571428\n",
      "0.6190476190476191\n",
      "0.4565217391304348\n",
      "0.8095238095238093\n",
      "0.7249999999999999\n",
      "1.0\n",
      "0.6\n",
      "0.6388888888888888\n",
      "0.4782608695652174\n",
      "0.5714285714285714\n",
      "0.625\n",
      "0.47619047619047616\n",
      "0.8333333333333333\n",
      "0.7\n",
      "0.8\n",
      "0.45454545454545453\n",
      "0.75\n",
      "0.75\n",
      "0.5833333333333334\n",
      "0.7000000000000001\n",
      "0.6666666666666666\n",
      "0.6190476190476191\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in zip(true, preds):\n",
    "    \n",
    "    score = roc_auc_score(i[0], i[1])\n",
    "    scores.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: \n"
     ]
    }
   ],
   "source": [
    "print('AUC: '.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_image(filename, from_path):\n",
    "    \n",
    "    if from_path == False:\n",
    "        \n",
    "        input_image = Image.open(filename)\n",
    "        transformed = transform(input_image)\n",
    "        filename = filename.split('/')[-1][:-5]\n",
    "        filename = 'data/processed_posters/{}-processed.jpeg'.format(filename)\n",
    "\n",
    "        output_image(transformed, filename)\n",
    "        return transformed\n",
    "\n",
    "    else:\n",
    "        \n",
    "        transformed = transform(Image.open(filename))\n",
    "        return transformed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def output_image(image, filename):\n",
    "    \n",
    "    image = ToPILImage()(invTrans(image))\n",
    "    image.save(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "processed = torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "film_ids = [i[13:-5] for i in df['poster_path'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = film_dataset(film_ids, encoded, processed, encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_plot(idx2wrd, plot):\n",
    "    \n",
    "    plot = [int(i) for i in list(plot)]\n",
    "    decoded = [idx2wrd[i] for i in plot if i != 0]\n",
    "    \n",
    "    return ' '.join(decoded[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_genre(genre, idx2genre):\n",
    "    \n",
    "    genre = [int(i) for i in list(genre)]\n",
    "    decoded = [idx2genre[i] for i in genre]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_genre(dataset[1]['genre'], idx2genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "    invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])\n",
    "    pil_image = ToPILImage()(invTrans(image))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = view_image(dataset[23]['poster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col, row in df.iterrows():\n",
    "    print(row)\n",
    "    genre = encode_genre(row['genre'], genre2idx)\n",
    "    plot = encode_plot(row['plot'], wrd2idx)\n",
    "    print(row['poster_path'])\n",
    "    poster = process_image(row['poster_path'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, wrd2idx, genre2idx):\n",
    "        \n",
    "        self.film_id = []\n",
    "        self.genre = []\n",
    "        self.plot = []\n",
    "        self.poster = []\n",
    "        self.failed = []\n",
    "        \n",
    "        self.wrd2idx = wrd2idx\n",
    "        self.genre2idx = genre2idx\n",
    "        \n",
    "        for col, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            self.film_id.append(row['id'])\n",
    "            self.genre.append(encode_genre(row['genre'], genre2idx))\n",
    "            self.plot.append(encode_plot(row['plot'], wrd2idx))\n",
    "            self.poster.append(process_image(row['poster_path'], True))\n",
    "            self.failed.append(row)\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = film_dataset(df[:50], wrd2idx, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, film_id, plot, poster, genre):\n",
    "        \n",
    "        self.film_id = film_id\n",
    "        self.plot = plot\n",
    "        self.poster = poster\n",
    "        self.genre = genre\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
