{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upto = 50\n",
    "test_upto = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('data/movie_db.csv')[:train_upto]\n",
    "test_csv = pd.read_csv('data/movie_db.csv')[train_upto:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Genre Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_genres(genre):\n",
    "    genre_set = []\n",
    "\n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "\n",
    "            if g not in genre_set:\n",
    "                genre_set.append(g)\n",
    "\n",
    "        idx2genre = dict(enumerate(genre_set))\n",
    "        genre2idx = {g : idx for idx, g in idx2genre.items()}\n",
    "    \n",
    "    return idx2genre, genre2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def count_genre(genre, genre2idx):\n",
    "    \n",
    "    genre_counts = {genre : 0 for genre in genre2idx.keys()}\n",
    "    \n",
    "    for i in genre:\n",
    "        \n",
    "        genres = i.split(',')\n",
    "        \n",
    "        for g in genres:\n",
    "\n",
    "            g = g.strip()\n",
    "            \n",
    "            genre_counts[g] += 1\n",
    "            \n",
    "    return genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode_genres(genres, genre2idx):\n",
    "    \n",
    "    encoded_genres = []\n",
    "    \n",
    "    vector_size = len(genre2idx)\n",
    "    \n",
    "    for i in genres:\n",
    "            \n",
    "        empty_vec = np.zeros(vector_size)    \n",
    "        encoded = [genre2idx[x.strip()] for x in i.split(',') if i in genre2idx]\n",
    "        \n",
    "        for i in encoded:\n",
    "            empty_vec[i] = 1\n",
    "            \n",
    "        encoded_genres.append(empty_vec)\n",
    "        \n",
    "    return encoded_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_genre(genre, genre2idx):\n",
    "    \n",
    "    encoded_genre = torch.LongTensor([genre2idx[g.strip()] for g in genre])\n",
    "        \n",
    "    return encoded_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = train_csv['genre'].tolist()\n",
    "test_genre = test_csv['genre'].tolist()\n",
    "idx2genre, genre2idx = get_genres(genre)\n",
    "genre_counts = count_genre(genre, genre2idx)\n",
    "encoded_genres = encode_genres(genre, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_genres = encode_genres(test_genre, genre2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Plot and Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def reg_remove(plot):\n",
    "    remove_non_words = re.compile(r'[^\\w -]')\n",
    "    clean = re.sub(remove_non_words, '', plot)\n",
    "    return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def build_vocab(plots, train=None):\n",
    "    \n",
    "    vocab = {}\n",
    "    processed_plots = []\n",
    "    \n",
    "    for plot in tqdm(plots):\n",
    "\n",
    "        plot = reg_remove(plot.lower()).split(' ')\n",
    "        plot.insert(0, '<start>')\n",
    "        plot.append('<end>')\n",
    "        \n",
    "        if train:\n",
    "            for token in plot:\n",
    "\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab) +1 \n",
    "        \n",
    "        processed_plots.append(plot)\n",
    "    \n",
    "    if train:\n",
    "        idx2wrd = {idx : wrd for wrd,idx in vocab.items()}\n",
    "        return vocab, idx2wrd, processed_plots\n",
    "    \n",
    "    return processed_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = train_csv['plot'].tolist()[:train_upto]\n",
    "test_plots=test_csv['plot'].tolist()[:test_upto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbb2a351fec4285b99d3dd7d119f3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrd2idx, idx2wrd, processed_plots = build_vocab(plots, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d33f694788447aa8a311a25a33cff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_processed_plots = build_vocab(test_plots, train=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode(plot, wrd2idx):\n",
    "    \n",
    "    encoded_plot = []\n",
    "    \n",
    "    for token in plot:\n",
    "        \n",
    "        if token in wrd2idx:\n",
    "            encoded_plot.append(wrd2idx[token])\n",
    "            \n",
    "        else:\n",
    "            encoded_plot.append(len(wrd2idx)+1)\n",
    "            \n",
    "    return encoded_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_plots(plots, wrd2idx):\n",
    "    \n",
    "    encoded = []\n",
    "    \n",
    "    for i in tqdm(plots):\n",
    "        encoded.append(torch.LongTensor(encode(i, wrd2idx)))\n",
    "        \n",
    "    return pad_sequence(encoded,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0e7dfa2f4b48a586b104ffe3f7db82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909347fe63e047fc9ec0c267ba59d3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded = encode_plots(processed_plots, wrd2idx)\n",
    "test_encoded = encode_plots(test_processed_plots, wrd2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "class FilmClassifier(Dataset):\n",
    "    \n",
    "    def __init__(self, df, X, y):\n",
    "        \n",
    "        self.df = df\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "    \n",
    "    def processed_path(self, path):\n",
    "        path = path.split('/')\n",
    "        path[1] = 'processed_posters'\n",
    "        x = path[2].split('.')\n",
    "        path[2] = '{}-processed.jpeg'.format(x[0])\n",
    "        return '/'.join(path)\n",
    "    \n",
    "    def process_image(self, filename, from_path=True):\n",
    "    \n",
    "        if from_path == False:\n",
    "\n",
    "            input_image = Image.open(filename)\n",
    "            transformed = transform(input_image)\n",
    "            filename = filename.split('/')[-1][:-5]\n",
    "            filename = 'data/processed_posters/{}-processed.jpeg'.format(filename)\n",
    "\n",
    "            output_image(transformed, filename)\n",
    "            return transformed\n",
    "\n",
    "        else:\n",
    "\n",
    "            transformed = transform(Image.open(filename))\n",
    "            return transformed\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {'id' : self.df.loc[idx]['id'],\n",
    "                'title' : self.df.loc[idx]['title'],\n",
    "                'genre' : self.df.loc[idx]['genre'],\n",
    "                'poster' : self.process_image(self.processed_path(self.df.loc[idx]['poster_path'])),\n",
    "                'plot' : self.df.loc[idx]['plot'],\n",
    "                'encoded_plot' : self.X[idx],\n",
    "                'encoded_genre' : self.y[idx]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FilmClassifier(train_csv, encoded, encoded_genres)\n",
    "test_dataset = FilmClassifier(test_csv, test_encoded, test_encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,shuffle=True, batch_size=2)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = super(SpatialDropout, self).forward(x)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        x = x.squeeze(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size, vocab_size, hidden_dim, \n",
    "                 embed_dim, n_layers, output_size, batch_size):\n",
    "        super(rnn, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.gru1 = nn.GRU(embed_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        self.gru2 = nn.GRU(hidden_dim, hidden_dim, bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim*2, 1)\n",
    "        self.fc_aux_out = nn.Linear(hidden_dim*2, output_size-1)\n",
    "        \n",
    "    def forward(self, x, features):\n",
    "        \n",
    "        embedded = self.embedding_dropout(self.embed(x))\n",
    "        h = features.expand(self.n_layers, -1,-1)\n",
    "        \n",
    "        print('Embedding Shape: {}'.format(embedded.shape))\n",
    "        #input_vec = torch.cat([embedded,features])\n",
    "        h_1, _ = self.gru1(embedded, h)\n",
    "        return h_1\n",
    "        print('1st LSTM: {}'.format(h_1))\n",
    "        return h_1\n",
    "        h_2, _ = self.lstm2(h_1)\n",
    "        \n",
    "        avg_pool = torch.mean(h_2, 1)\n",
    "        max_pool, _ = torch.max(h_2, 1)\n",
    "        \n",
    "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
    "        \n",
    "        h_lin_1 = F.relu(self.fc1(h_conc))\n",
    "        h_li_2 = F.relu(self.fc2(h_conc))\n",
    "        h_conc_linear = torch.cat((h_lin_1, h_li_2), 1)\n",
    "        \n",
    "        hidden = h_conc + h_conc_linear\n",
    "        result = self.fc_out(hidden)\n",
    "        \n",
    "        aux_result = self.fc_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(wrd2idx) + 2\n",
    "embed_dim = 300\n",
    "hidden_dim=256\n",
    "output_size = len(genre2idx)\n",
    "input_size=623\n",
    "n_layers = 1\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn(input_size, vocab_size, hidden_dim,\n",
    "            embed_dim, n_layers, output_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lrs = [{'params': param, 'lr': lr} for param in model.parameters()]\n",
    "optimizer = torch.optim.Adam(param_lrs, lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "NUM_EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn(\n",
       "  (embed): Embedding(1653, 300)\n",
       "  (embedding_dropout): SpatialDropout(p=0.3, inplace=False)\n",
       "  (lstm1): LSTM(300, 256, batch_first=True)\n",
       "  (lstm2): LSTM(256, 256, batch_first=True)\n",
       "  (gru1): GRU(300, 256, batch_first=True)\n",
       "  (gru2): GRU(256, 256, batch_first=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc_out): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (fc_aux_out): Linear(in_features=512, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/robertthomas/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6b2af83c734b43acdd9365930cb4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5616baeb00409398bb748a6af7a3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "for epoch in tqdm(range(0, NUM_EPOCHS), total=NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for i in tqdm(train_dataloader):\n",
    "\n",
    "        x = i['encoded_plot'].to(device)\n",
    "        y = i['encoded_genre'].to(device)\n",
    "        img = i['poster']\n",
    "        \n",
    "        features = feature_extractor(img)\n",
    "        features=features.transpose(0,2).transpose(1,3).squeeze(0) \n",
    "        out = model(x, features)\n",
    "#         loss = criterion(out, y)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         avg_loss += loss.item() / len(train_dataloader)\n",
    "\n",
    "\n",
    "        break\n",
    "\n",
    "    break\n",
    "    print(avg_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.expand(2,2,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 512])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features* torch.Tensor(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model = train(train_dataloader, model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(preds):\n",
    "    empty = []\n",
    "    \n",
    "    for i in preds:\n",
    "        if i > 0.5:\n",
    "            empty.append(1)\n",
    "            \n",
    "        else:\n",
    "            empty.append(0)\n",
    "            \n",
    "    return empty\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trained_model, test_dataloader, urlystop):\n",
    "    preds = []\n",
    "    true = []\n",
    "    model.eval()\n",
    "    model.to('cuda:1')\n",
    "\n",
    "    num = 0\n",
    "    for i in tqdm(test_dataloader, total=urlystop):\n",
    "\n",
    "        if num == urlystop:\n",
    "            break\n",
    "        x = i[0].to('cuda:1')\n",
    "        y = i[1].to('cuda:1')\n",
    "\n",
    "        out = model(x)\n",
    "        pred = sigmoid(out.cpu().detach().numpy())\n",
    "        preds.append(get_index(pred[0]))\n",
    "        true.append(y.cpu().numpy()[0])\n",
    "        num += 1\n",
    "    \n",
    "    return np.array(preds), np.array(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f08475211140afb5ca393d9828167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1592.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pres, true = test(trained_model, test_dataloader, len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricsReport(modelName, test_labels, predictions):\n",
    "    ModelsPerformance = {}\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro', zero_division=True)\n",
    "\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro', zero_division=True)\n",
    "    \n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    \n",
    "    ModelsPerformance[modelName] = micro_f1\n",
    "    \n",
    "    return ModelsPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = metricsReport('Micro-F1 Score', true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Micro-F1 Score': 0.5105733082706767}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = np.all(pres == true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += sum(np.logical_and(y_true[i], y_pred[i])) / sum(np.logical_or(y_true[i], y_pred[i]))\n",
    "    \n",
    "    return temp / y_true.shape[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38343677713966584"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_true[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_true[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5074845955970327"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(y_true, y_pred):\n",
    "    temp = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if sum(y_pred[i]) == 0:\n",
    "            continue\n",
    "        temp+= sum(np.logical_and(y_true[i], y_pred[i]))/ sum(y_pred[i])\n",
    "    return temp/ y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5647478463747304"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamming_Loss(y_true, y_pred):\n",
    "    temp=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        temp += np.size(y_true[i] == y_pred[i]) - np.count_nonzero(y_true[i] == y_pred[i])\n",
    "    return temp/(y_true.shape[0] * y_true.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10903475711892797"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hamming_Loss(true, pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = multilabel_confusion_matrix(true,pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in zip(true, pres):\n",
    "    \n",
    "    score = roc_auc_score(i[0], i[1])\n",
    "    scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7276377400910997"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "print('AUC: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(448),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filename, from_path):\n",
    "    \n",
    "    if from_path == False:\n",
    "        \n",
    "        input_image = Image.open(filename)\n",
    "        transformed = transform(input_image)\n",
    "        filename = filename.split('/')[-1][:-5]\n",
    "        filename = 'data/processed_posters/{}-processed.jpeg'.format(filename)\n",
    "\n",
    "        output_image(transformed, filename)\n",
    "        return transformed\n",
    "\n",
    "    else:\n",
    "        \n",
    "        transformed = transform(Image.open(filename))\n",
    "        return transformed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_image(image, filename):\n",
    "    \n",
    "    image = ToPILImage()(invTrans(image))\n",
    "    image.save(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ids = [i[13:-5] for i in df['poster_path'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = film_dataset(film_ids, encoded, processed, encoded_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_plot(idx2wrd, plot):\n",
    "    \n",
    "    plot = [int(i) for i in list(plot)]\n",
    "    decoded = [idx2wrd[i] for i in plot if i != 0]\n",
    "    \n",
    "    return ' '.join(decoded[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_genre(genre, idx2genre):\n",
    "    \n",
    "    genre = [int(i) for i in list(genre)]\n",
    "    decoded = [idx2genre[i] for i in genre]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_genre(dataset[1]['genre'], idx2genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(image):\n",
    "    invTrans = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], \n",
    "                                                     std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "                               ])\n",
    "    pil_image = ToPILImage()(invTrans(image))\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = view_image(dataset[23]['poster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col, row in df.iterrows():\n",
    "    print(row)\n",
    "    genre = encode_genre(row['genre'], genre2idx)\n",
    "    plot = encode_plot(row['plot'], wrd2idx)\n",
    "    print(row['poster_path'])\n",
    "    poster = process_image(row['poster_path'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, wrd2idx, genre2idx):\n",
    "        \n",
    "        self.film_id = []\n",
    "        self.genre = []\n",
    "        self.plot = []\n",
    "        self.poster = []\n",
    "        self.failed = []\n",
    "        \n",
    "        self.wrd2idx = wrd2idx\n",
    "        self.genre2idx = genre2idx\n",
    "        \n",
    "        for col, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            self.film_id.append(row['id'])\n",
    "            self.genre.append(encode_genre(row['genre'], genre2idx))\n",
    "            self.plot.append(encode_plot(row['plot'], wrd2idx))\n",
    "            self.poster.append(process_image(row['poster_path'], True))\n",
    "            self.failed.append(row)\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = film_dataset(df[:50], wrd2idx, genre2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class film_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, film_id, plot, poster, genre):\n",
    "        \n",
    "        self.film_id = film_id\n",
    "        self.plot = plot\n",
    "        self.poster = poster\n",
    "        self.genre = genre\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return {\n",
    "            'film_id' : self.film_id[idx],\n",
    "            'plot'    : self.plot[idx],\n",
    "            'poster'  : self.poster[idx],\n",
    "            'genre'   : self.genre[idx]\n",
    "        }\n",
    "        \n",
    "    def __len__(sef):\n",
    "        return len(film_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
